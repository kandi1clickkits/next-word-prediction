{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d06508f",
   "metadata": {},
   "source": [
    "## Next Word Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c688619",
   "metadata": {},
   "source": [
    "Predicts the next possible word given the input text sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3db1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input text sequence\n",
    "text_seq = \"I'm gonna make him an offer he can't\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b878297",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e414e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82aaa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self):\n",
    "        super(GPT2, self).__init__()\n",
    "\n",
    "        self.model_type = \"GPT2\"\n",
    "\n",
    "        # Load pre-trained model tokenizer (vocabulary)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "        # Load pre-trained model (weights)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "    def predict_next(self, text, k):\n",
    "        # Encode a text inputs\n",
    "        indexed_tokens = self.tokenizer.encode(text)\n",
    "\n",
    "        # Convert indexed tokens in a PyTorch tensor\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "        # Set the model in evaluation mode to deactivate the DropOut modules\n",
    "        self.model.eval()\n",
    "\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        tokens_tensor = tokens_tensor.to(device)\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        # Get the predicted next sub-word\n",
    "        probs = predictions[0, -1, :]\n",
    "        top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(k)[1]]\n",
    "\n",
    "        return top_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d2f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates an instance, where pretrained GPT2 model gets loaded\n",
    "gpt2 = GPT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8709746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['refuse', 'resist', 'take', 'deny', 'get']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call predict method to predict next possible words\n",
    "gpt2.predict_next(text_seq, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c82e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207b3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1716528",
   "metadata": {},
   "source": [
    "### Customisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5544",
   "metadata": {},
   "source": [
    "A mock interface with a prompt to keep predicting next possible word for given input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c601d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text sequence(or type 'exit' to exit): I would\n",
      "['like', 'have', 'say', 'be', 'not']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like\n",
      "['to', 'you', 'the', 'a', 'it']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to\n",
      "['thank', 'see', 'say', 'ask', 'add']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank\n",
      "['the', 'you', 'all', 'everyone', 'my']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you\n",
      "['for', 'all', ',', '.', 'very']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all\n",
      "['for', '.', ',', 'and', 'so']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for\n",
      "['your', 'the', 'being', 'taking', 'supporting']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being\n",
      "['patient', 'so', 'part', 'with', 'a']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being part\n",
      "['of', 'and', '.', 'the', ',']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being part of\n",
      "['the', 'this', 'our', 'my', 'a']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being part of this\n",
      "['amazing', 'great', 'project', 'wonderful', 'journey']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being part of this wonderful\n",
      "['community', 'project', 'journey', 'event', 'and']\n",
      "Enter a text sequence(or type 'exit' to exit): I would like to thank you all for being part of this wonderful community\n",
      "['.', 'and', ',', 'of', '!']\n",
      "Enter a text sequence(or type 'exit' to exit): exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    inp_txt = input(\"Enter a text sequence(or type 'exit' to exit): \")\n",
    "    if inp_txt == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        print(gpt2.predict_next(inp_txt, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692c5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
